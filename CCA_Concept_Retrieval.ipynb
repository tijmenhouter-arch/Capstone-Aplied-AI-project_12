import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
import torch

# 1. LAAD DE DATA EN HET MODEL
# ---------------------------
# Laad de dataframe die je in de vorige stap hebt opgeslagen
df = pd.read_parquet("WG_MPs_LaBSE_Embeddings.parquet")

# Zet de embeddings (die nu lijsten zijn in de dataframe) om naar een grote matrix voor snelle berekening
# Dit is essentieel voor de snelheid van cosine similarity
corpus_embeddings = np.stack(df['embedding'].values)

# Laad exact hetzelfde model als waarmee je de chunks hebt gemaakt
model = SentenceTransformer('sentence-transformers/LaBSE')

# 2. DEFINIEER DE IPCC CONCEPTEN (QUERIES)
# ----------------------------------------
# Volgens je Project Plan moet je IPCC definities gebruiken.
# Hier zijn een paar voorbeelden. Je kunt deze lijst uitbreiden met meer termen uit de IPCC glossary.
ipcc_concepts = {
    "Adaptation": "The process of adjustment to actual or expected climate and its effects. In human systems, adaptation seeks to moderate or avoid harm or exploit beneficial opportunities.",
    "Resilience": "The capacity of social, economic and environmental systems to cope with a hazardous event or trend or disturbance, responding or reorganizing in ways that maintain their essential function, identity and structure.",
    "Mitigation": "A human intervention to reduce the sources or enhance the sinks of greenhouse gases.",
    "Flood Risk": "The potential for adverse consequences where something of value is at stake and where the outcome is uncertain, specifically related to coastal or riverine flooding.",
    "Heat Stress": "The sensation of discomfort and physiological strain produced by exposure to uncomfortably hot environments, often relevant in urban heritage contexts."
}

# 3. VOER DE RETRIEVAL UIT (PIPELINE)
# -----------------------------------
print(f"Start retrieval voor {len(ipcc_concepts)} concepten...\n")

results = []

for concept, definition in ipcc_concepts.items():
    # A. Embed de query (de definitie van het concept)
    query_embedding = model.encode(definition)
    
    # B. Bereken Cosine Similarity tussen de query en ALLE chunks
    # util.cos_sim geeft een score tussen -1 en 1
    scores = util.cos_sim(query_embedding, corpus_embeddings)[0]
    
    # C. Haal de top 5 resultaten op
    # torch.topk is heel snel in het vinden van de hoogste waardes
    top_results = torch.topk(scores, k=5)
    
    print(f"--- Top matches voor concept: '{concept}' ---")
    for score, idx in zip(top_results.values, top_results.indices):
        idx = int(idx) # Zorg dat het een integer is voor de dataframe lookup
        
        # Haal de tekst en metadata op uit de dataframe
        original_text = df.iloc[idx]['text_chunk']
        mp_index = df.iloc[idx]['mp_index']
        
        # Sla het resultaat op voor latere analyse
        results.append({
            "Concept": concept,
            "Score": score.item(),
            "MP_Index": mp_index,
            "Text_Snippet": original_text[:200] + "...", # Eerste 200 tekens voor overzicht
            "Full_Text": original_text
        })
        
        print(f"Score: {score:.4f} | MP Doc: {mp_index}")
        print(f"Text: {original_text[:150]}...\n")

# 4. EXPORTEER DE RESULTATEN
# --------------------------
# Zet de resultaten in een DataFrame voor de 'Writing Team' analyse
df_results = pd.DataFrame(results)

# Sla op als CSV of Excel voor het rapport
df_results.to_csv("Retrieval_Results_CCA_Concepts.csv", index=False)
print("Klaar! Resultaten opgeslagen in 'Retrieval_Results_CCA_Concepts.csv'.")
